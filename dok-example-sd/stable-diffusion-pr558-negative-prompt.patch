diff --git a/README.md b/README.md
index c9e6c3bb1..8d0283abc 100644
--- a/README.md
+++ b/README.md
@@ -105,13 +105,14 @@ and renders images of size 512x512 (which it was trained on) in 50 steps. All su
 
 
 ```commandline
-usage: txt2img.py [-h] [--prompt [PROMPT]] [--outdir [OUTDIR]] [--skip_grid] [--skip_save] [--ddim_steps DDIM_STEPS] [--plms] [--laion400m] [--fixed_code] [--ddim_eta DDIM_ETA]
+usage: txt2img.py [-h] [--prompt [PROMPT]] [--negative_prompt] [--outdir [OUTDIR]] [--skip_grid] [--skip_save] [--ddim_steps DDIM_STEPS] [--plms] [--laion400m] [--fixed_code] [--ddim_eta DDIM_ETA]
                   [--n_iter N_ITER] [--H H] [--W W] [--C C] [--f F] [--n_samples N_SAMPLES] [--n_rows N_ROWS] [--scale SCALE] [--from-file FROM_FILE] [--config CONFIG] [--ckpt CKPT]
                   [--seed SEED] [--precision {full,autocast}]
 
 optional arguments:
   -h, --help            show this help message and exit
   --prompt [PROMPT]     the prompt to render
+  --negative_prompt     the negative prompt to render
   --outdir [OUTDIR]     dir to write results to
   --skip_grid           do not save a grid, only individual samples. Helpful when evaluating lots of samples
   --skip_save           do not save individual samples. For speed measurements.
diff --git a/scripts/img2img.py b/scripts/img2img.py
index 421e2151d..a553b39be 100644
--- a/scripts/img2img.py
+++ b/scripts/img2img.py
@@ -67,7 +67,15 @@ def main():
         default="a painting of a virus monster playing guitar",
         help="the prompt to render"
     )
-
+    
+    parser.add_argument(
+        "--negative_prompt",
+        type=str,
+        nargs="?",
+        default="",
+        help="the negative prompt to render"
+    )
+    
     parser.add_argument(
         "--init-img",
         type=str,
@@ -215,6 +223,7 @@ def main():
     n_rows = opt.n_rows if opt.n_rows > 0 else batch_size
     if not opt.from_file:
         prompt = opt.prompt
+        negative_prompt = opt.negative_prompt
         assert prompt is not None
         data = [batch_size * [prompt]]
 
@@ -249,8 +258,10 @@ def main():
                 for n in trange(opt.n_iter, desc="Sampling"):
                     for prompts in tqdm(data, desc="data"):
                         uc = None
-                        if opt.scale != 1.0:
-                            uc = model.get_learned_conditioning(batch_size * [""])
+                        if negative_prompt:
+                            uc = model.get_learned_conditioning(batch_size * [negative_prompt])
+                        elif opt.scale != 1.0:
+                            uc = model.get_learned_conditioning(batch_size * [""])
                         if isinstance(prompts, tuple):
                             prompts = list(prompts)
                         c = model.get_learned_conditioning(prompts)
diff --git a/scripts/txt2img.py b/scripts/txt2img.py
index bc3864043..84905c059 100644
--- a/scripts/txt2img.py
+++ b/scripts/txt2img.py
@@ -105,6 +105,15 @@ def main():
         default="a painting of a virus monster playing guitar",
         help="the prompt to render"
     )
+    
+    parser.add_argument(
+        "--negative_prompt",
+        type=str,
+        nargs="?",
+        default="",
+        help="the negative prompt to render"
+    )
+    
     parser.add_argument(
         "--outdir",
         type=str,
@@ -267,6 +276,7 @@ def main():
     n_rows = opt.n_rows if opt.n_rows > 0 else batch_size
     if not opt.from_file:
         prompt = opt.prompt
+        negative_prompt = opt.negative_prompt
         assert prompt is not None
         data = [batch_size * [prompt]]
 
@@ -294,8 +304,11 @@ def main():
                 for n in trange(opt.n_iter, desc="Sampling"):
                     for prompts in tqdm(data, desc="data"):
                         uc = None
-                        if opt.scale != 1.0:
+                        if negative_prompt:
+                            uc = model.get_learned_conditioning(batch_size * [negative_prompt])
+                        elif opt.scale != 1.0:
                             uc = model.get_learned_conditioning(batch_size * [""])
+                            
                         if isinstance(prompts, tuple):
                             prompts = list(prompts)
                         c = model.get_learned_conditioning(prompts)
